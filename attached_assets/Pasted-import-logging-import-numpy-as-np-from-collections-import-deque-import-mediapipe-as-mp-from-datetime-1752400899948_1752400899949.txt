import logging
import numpy as np
from collections import deque
import mediapipe as mp
from datetime import datetime, timedelta

# Landmark indices for clarity
NOSE = 0
LEFT_EYE_INNER = 1
LEFT_EYE = 2
LEFT_EYE_OUTER = 3
RIGHT_EYE_INNER = 4
RIGHT_EYE = 5
RIGHT_EYE_OUTER = 6
LEFT_SHOULDER = 11
RIGHT_SHOULDER = 12
LEFT_HIP = 23
RIGHT_HIP = 24

class PostureAnalyzer:
    """
    Robust posture analyzer detecting:
      - sitting_straight
      - hunching_over
      - lying
      - leaning_forward
      - left_sitting
      - right_sitting
      - standing
    Provides full 3D head orientation and spine angle metrics.
    """
    def __init__(self,
                 history_duration=timedelta(hours=2),
                 angle_thresholds=None,
                 quality_thresholds=None):
        self.logger = logging.getLogger(__name__)
        self.logger.info("PostureAnalyzer initialized")

        # MediaPipe pose setup
        self.pose = mp.solutions.pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            enable_segmentation=False,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )

        # History
        self.history_duration = history_duration
        self.posture_history = deque()

        # Thresholds
        self.angle_thresholds = angle_thresholds or {
            'hunch': 20.0,
            'lean_forward': 10.0,
            'lying': 45.0,
            'left_shift': 0.05,
            'right_shift': 0.05,
        }
        self.quality_thresholds = quality_thresholds or {
            'excellent': 10.0,
            'good': 15.0,
            'fair': 20.0,
            'poor': float('inf')
        }

    def analyze(self, image):
        # Convert to RGB
        img_rgb = _ensure_rgb(image)
        results = self.pose.process(img_rgb)
        if not results.pose_landmarks:
            return self._no_person_response()

        lm = results.pose_landmarks.landmark
        metrics = self._compute_metrics(lm)
        posture = self._classify_posture(metrics)
        quality = self._determine_quality(metrics['spine_angle'])

        result = {
            'posture': posture,
            'quality': quality,
            **metrics,
            'timestamp': datetime.now()
        }
        self._record_history(result)
        return result

    def _compute_metrics(self, lm):
        # Head orientation: yaw (horizontal), pitch (vertical) from nose and eyes
        eye_center = np.array([(lm[LEFT_EYE].x + lm[RIGHT_EYE].x) / 2,
                                (lm[LEFT_EYE].y + lm[RIGHT_EYE].y) / 2])
        nose = np.array([lm[NOSE].x, lm[NOSE].y])
        vec = nose - eye_center
        yaw = np.degrees(np.arctan2(vec[0], 1e-3))
        pitch = np.degrees(np.arctan2(vec[1], 1e-3))

        # Spine angle: line between shoulders vs hips
        left_sh = np.array([lm[LEFT_SHOULDER].x, lm[LEFT_SHOULDER].y])
        right_sh = np.array([lm[RIGHT_SHOULDER].x, lm[RIGHT_SHOULDER].y])
        shoulder_mid = (left_sh + right_sh) / 2
        left_hip = np.array([lm[LEFT_HIP].x, lm[LEFT_HIP].y])
        right_hip = np.array([lm[RIGHT_HIP].x, lm[RIGHT_HIP].y])
        hip_mid = (left_hip + right_hip) / 2
        spinal_vec = shoulder_mid - hip_mid
        spine_angle = abs(np.degrees(np.arctan2(spinal_vec[1], spinal_vec[0])) - 90)

        # Lateral shift: hip midpoint x vs shoulder midpoint x
        lateral_shift = hip_mid[0] - shoulder_mid[0]

        return {
            'yaw': yaw,
            'pitch': pitch,
            'spine_angle': spine_angle,
            'lateral_shift': lateral_shift
        }

    def _classify_posture(self, m):
        a = m['spine_angle']
        s = m['lateral_shift']
        if a > self.angle_thresholds['lying']:
            return 'lying'
        if a > self.angle_thresholds['hunch']:
            return 'hunching_over'
        if abs(s) > self.angle_thresholds['left_shift'] and s < 0:
            return 'left_sitting'
        if abs(s) > self.angle_thresholds['right_shift'] and s > 0:
            return 'right_sitting'
        if a > self.angle_thresholds['lean_forward']:
            return 'leaning_forward'
        return 'sitting_straight'

    def _determine_quality(self, angle):
        for q, t in self.quality_thresholds.items():
            if angle < t:
                return q
        return 'poor'

    def _record_history(self, entry):
        self.posture_history.append(entry)
        cutoff = datetime.now() - self.history_duration
        while self.posture_history and self.posture_history[0]['timestamp'] < cutoff:
            self.posture_history.popleft()

    def get_trend(self, minutes=60):
        cutoff = datetime.now() - timedelta(minutes=minutes)
        recent = [e for e in self.posture_history if e['timestamp'] >= cutoff]
        if not recent:
            return {'trend': 'neutral', 'recommendation': 'No data.'}
        counts = {}
        for e in recent:
            counts[e['quality']] = counts.get(e['quality'], 0) + 1
        avg_angle = sum(e['spine_angle'] for e in recent) / len(recent)
        # simplistic trend
        trend = 'positive' if counts.get('excellent',0)+counts.get('good',0) > len(recent)/2 else 'negative'
        rec = 'Keep it up!' if trend=='positive' else 'Try to improve posture.'
        return {'trend': trend, 'average_angle': avg_angle, 'counts': counts, 'recommendation': rec}

    def _no_person_response(self):
        return {
            'posture': 'unknown',
            'quality': 'unknown',
            'yaw': 0.0,
            'pitch': 0.0,
            'spine_angle': 0.0,
            'lateral_shift': 0.0,
            'timestamp': datetime.now()
        }


def _ensure_rgb(image):
    if image.ndim == 2:
        return np.stack([image]*3, axis=-1)
    if image.shape[2] == 4:
        return image[..., :3]
    return image
